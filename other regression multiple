###load directory####

setwd("E:/Maestría/Maestría_Universidad/2025-1/Biología cuantitativa/13-03-25//")

# Load dataset
data <- read.csv("species_gam-mod-manual.csv") #Archivo hecho manual, eliminando laprimera columna y moviendo especies al final

#Modificación del documento directo con codigo

data <- data[, -1]

# Mover la columna "especies" al final
data <-data %>%
  select(-species, species)

# Ver la tabla modificada
head(data)

# Correlation analysis plot - Exploración de los datos para ver cuáles variables se correlación
chart.Correlation(data, histogram=TRUE, pch=19)

#Normal linear regresion
m1<- lm(species~ Y + bio_1 + bio_12 + bio_15 + bio_2 + bio_3, data=data)

m2<-lm(species~ Y + I (Y^2) + bio_1 + I (bio_1^2) + bio_12 + bio_15 + I(bio_15^2) + bio_2 + bio_3, data=data)

m3<-lm(species~ bio_1 + I (bio_1^2) + bio_12 + bio_15 + I(bio_15^2) + bio_2 + bio_3, data=data)

AICc(m1, m2)

summary(m1)
summary(m2)

#Nos saltamos a plotear el modelo 1


# normal linear regression - Voy a crear una nueva estadistica con lm (linearmodel - para hacer la regraciónlineal)
m1<- lm(Abundance ~ av_litter_depth, data=data)
summary(m1)
m2<- lm(Abundance ~ trees_over_3m, data=data)
summary(m2)
m2.1<- lm(Abundance ~ av_slope, data=data)
summary(m2.1)
m3<- lm(Abundance ~ trees_over_3m + I(trees_over_3m^2), data=data) #Modelo cuadratico
summary(m3)

predict(m1, newdata = data.frame(av_litter_depth = 4)) #predice, en este caso, a una profundidad de 4, cuántas espescies se encontrarían

par(mfrow=c(2,2)) #Para plotear las asunciones del modelo, poniendo 2 columnas y dos filas en el mismo gráfico.
plot(m1)

#SALTO A MUMIN

# Predictions with confidence intervals - plotear el modelo con intervalos de confianza
predictions <- predict(m1, newdata=data, interval="confidence")
data$predicted <- predictions[, "fit"]
data$lwr <- predictions[, "lwr"] #crear el intervalo de confianza abajo
data$upr <- predictions[, "upr"] #Crear el intervalo de confianza arriba

# Plot predicted values with 95% confidence interval - Generar el gráfico
ggplot(data, aes(x=av_litter_depth, y=Abundance)) + 
  geom_point() +
  geom_line(aes(y=predicted), color="red") +
  geom_ribbon(aes(ymin=lwr, ymax=upr), alpha=0.2, fill="blue") +
  ggtitle("Abundance vs. Average Litter Depth") +
  xlab("Average Litter Depth") +
  ylab("Abundance")



##multiple linear regression

m4<- lm(Abundance ~ canopy_cover + av_slope + trees_over_3m + av_litter_depth, data=data)
summary(m4)



# Model assumption checks
par(mfrow=c(2,2))
plot(m4)  # Includes residuals vs. fitted, Q-Q plot, scale-location, and residuals vs. leverage
plot(m4, 4) #Distancia de Cook. La influencia del cook distance es significativa cuándo esmayor a 0,3.

# Model validation plots using broom ###ERROR!!!! REVISAR!!!
validation_data <- augment(m4)
validation_data

# Residuals vs. Fitted values
ggplot(validation_data, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("Residuals vs Fitted Values (Multiple Regression)") +
  xlab("Fitted Values") +
  ylab("Residuals")

# Q-Q Plot
ggplot(validation_data, aes(sample = .std.resid)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("Q-Q Plot of Standardized Residuals (Multiple Regression)")

# Cook's Distance plot
ggplot(validation_data, aes(x = seq_along(.cooksd), y = .cooksd)) +
  geom_bar(stat = "identity") +
  ggtitle("Cook's Distance (Multiple Regression)") +
  xlab("Observation Index") +
  ylab("Cook's Distance")


# Standardize predictor variables (center = TRUE, scale = TRUE) - Centrar el promedio y dividir por la variación estandar.
data_scaled <- data %>% 
  mutate(
    canopy_cover = as.numeric(scale(canopy_cover, center = TRUE, scale = TRUE)),
    av_slope = as.numeric(scale(av_slope, center = TRUE, scale = TRUE)),
    trees_over_3m = as.numeric(scale(trees_over_3m, center = TRUE, scale = TRUE)),
    av_litter_depth = as.numeric(scale(av_litter_depth, center = TRUE, scale = TRUE))
  )

### Multiple linear regression with standardized predictors ###Cambian las pendientes,para eso se estandarizaron las variables, SÓLO VARÍAN LAS PENDIENTES.
m5 <- lm(Abundance ~ canopy_cover + av_slope + trees_over_3m + av_litter_depth, data=data_scaled)
summary(m5)


###plot coeficcients## ESTIMA LOS INTERVALOS DE CONFIANZA DE MANERA ROBUSTA (robust)

plot_summs(m5, robust = TRUE)

###plot partial regression### Plotear la profundidad de la hojarasca, teniendo en cuenta que las otras variables son constantes, y los residuales parciales. Me da en negativo,por que son los valores estandarizados

effect_plot(m5, pred = av_litter_depth, partial.residuals = TRUE, interval = TRUE, plot.points = TRUE, 
            jitter = 0.05)

#En un modelo con variables no estandarizadas
effect_plot(m4, pred = av_litter_depth, partial.residuals = TRUE, interval = TRUE, plot.points = TRUE, 
            jitter = 0.05)

avPlots(m4) #Da las regresiones parciales para cada una de las variables (es decir, que las demás variables son constantes).

# Partial regression plots using ggpredict # Predice los efectos parciales.
ggplot(ggpredict(m5, terms="av_litter_depth"), aes(x=x, y=predicted)) +
  geom_point(data=data_scaled, aes(x=av_litter_depth, y=Abundance), alpha=0.5) +
  geom_line() +
  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha=0.2) +
  ggtitle("Partial Effect of av_litter_depth on Abundance") +
  xlab("Canopy Cover") +
  ylab("Predicted Abundance")

###choosing the best model###

#MODEL SELECTION forward and backward

library(MASS)

mfull <- lm(Abundance ~ canopy_cover + av_slope + trees_over_3m + av_litter_depth, data=data_scaled)

step <- stepAIC(mfull, trace = FALSE) #Hacer el forwart y reverse o both (ambos).
step$anova
step

#Model selection 2 #Crear modelo y comparar AICc

AICc(m3) #MODELO NO CUADRATICO
AICc(m4) #
BIC(m1)
BIC(m2)

###Model selection 3

# Model selection using AICc (MuMIn package)
options(na.action = "na.fail")  # Required for dredge function
model_selection <- dredge(m1, rank = "AICc") #Ranquearlos modelos por el AICc (FUNCIÓN DREDGE)
print(model_selection) 

# Best model based on AICc
best_model <- get.models(model_selection, subset = 1)[[1]]
summary(best_model)

AVER <-lm(species ~ bio_1 + bio_12 + bio_15 + bio_3 + Y + I(Y^2),
            data = data)

AICc(AVER, m1)

###R-squares### Calcular los R cuadrado parciales. En este caso se sabemos que el mejor modelo es la profundidad de hojarasca, pero para este ejercicio se usará el modelo que incluye todas las variables, porque nuestroo mejor modelo sólo tiene una variable. No es lo correcto, pero es para el ejecicio.

install.packages('rsq')
library(rsq)
rsq(mfull)

# Partial R-squared for each predictor variable
partial_rsq <- rsq.partial(mfull)
print(partial_rsq)


####variable contribution## Hace todas las combinaciones del orden de las varibales, para ver cuál es el mejor R-squared. Serían los R-squared

install.packages("relaimpo")

library(relaimpo)

# Percentage contribution of each predictor variable
importance <- calc.relimp(mfull, type = "lmg")
print(importance)


##################################################################
#Hacerlo con el otro archivo

###load directory####

setwd("E:/Maestría/Maestría_Universidad/2025-1/Biología cuantitativa/6-3-25/")

# Load dataset
data1 <- read.csv("Kiekie_variables.csv")


# Correlation analysis plot - Exploración de los datos para ver cuáles variables se correlación
chart.Correlation(data1, histogram=TRUE, pch=19)


# normal linear regression - Voy a crear una nueva estadistica con lm (linearmodel - para hacer la regraciónlineal)
m1<- lm(Abundance ~ av_litter_depth, data=data1)
summary(m1)
m2<- lm(Abundance ~ trees_over_3m, data=data1)
summary(m2)
m2.1<- lm(Abundance ~ av_slope, data=data1)
summary(m2.1)
m3<- lm(Abundance ~ trees_over_3m + I(trees_over_3m^2), data=data1) #Modelo cuadratico
summary(m3)

predict(m1, newdata = data.frame(av_litter_depth = 4)) #predice, en este caso, a una profundidad de 4, cuántas espescies se encontrarían

par(mfrow=c(2,2)) #Para plotear las asunciones del modelo, poniendo 2 columnas y dos filas en el mismo gráfico.
plot(m1)


# Predictions with confidence intervals - plotear el modelo con intervalos de confianza
predictions <- predict(m1, newdata=data1, interval="confidence")
data1$predicted <- predictions[, "fit"]
data1$lwr <- predictions[, "lwr"] #crear el intervalo de confianza abajo
data1$upr <- predictions[, "upr"] #Crear el intervalo de confianza arriba

# Plot predicted values with 95% confidence interval - Generar el gráfico
ggplot(data1, aes(x=av_litter_depth, y=Abundance)) + 
  geom_point() +
  geom_line(aes(y=predicted), color="red") +
  geom_ribbon(aes(ymin=lwr, ymax=upr), alpha=0.2, fill="blue") +
  ggtitle("Abundance vs. Average Litter Depth") +
  xlab("Average Litter Depth") +
  ylab("Abundance")



##multiple linear regression

m7<- lm(Abundance ~ av_scope + I(trees_over_3m^2), data=data) #Modelo cuadratico
summary(m8) ##REVISAAAAAR!!!


m8<- lm(Abundance ~ canopy_cover + av_slope + trees_over_3m + av_litter_depth, data=data1)
summary(m8)



# Model assumption checks
par(mfrow=c(2,2))
plot(m8)  # Includes residuals vs. fitted, Q-Q plot, scale-location, and residuals vs. leverage
plot(m8, 4) #Distancia de Cook. La influencia del cook distance es significativa cuándo esmayor a 0,3.

# Model validation plots using broom 
validation_data <- augment(m8)
validation_data

# Residuals vs. Fitted values
ggplot(validation_data, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  ggtitle("Residuals vs Fitted Values (Multiple Regression)") +
  xlab("Fitted Values") +
  ylab("Residuals")

# Q-Q Plot
ggplot(validation_data, aes(sample = .std.resid)) +
  stat_qq() +
  stat_qq_line() +
  ggtitle("Q-Q Plot of Standardized Residuals (Multiple Regression)")

# Cook's Distance plot
ggplot(validation_data, aes(x = seq_along(.cooksd), y = .cooksd)) +
  geom_bar(stat = "identity") +
  ggtitle("Cook's Distance (Multiple Regression)") +
  xlab("Observation Index") +
  ylab("Cook's Distance")


# Standardize predictor variables (center = TRUE, scale = TRUE) - Centrar el promedio y dividir por la variación estandar.
data_scaled <- data1 %>% 
  mutate(
    canopy_cover = as.numeric(scale(canopy_cover, center = TRUE, scale = TRUE)),
    av_slope = as.numeric(scale(av_slope, center = TRUE, scale = TRUE)),
    trees_over_3m = as.numeric(scale(trees_over_3m, center = TRUE, scale = TRUE)),
    av_litter_depth = as.numeric(scale(av_litter_depth, center = TRUE, scale = TRUE))
  )

### Multiple linear regression with standardized predictors ###Cambian las pendientes,para eso se estandarizaron las variables, SÓLO VARÍAN LAS PENDIENTES.
m10 <- lm(Abundance ~ canopy_cover + av_slope + trees_over_3m + av_litter_depth, data=data_scaled)
summary(m10)


###plot coeficcients## ESTIMA LOS INTERVALOS DE CONFIANZA DE MANERA ROBUSTA (robust)

plot_summs(m10, robust = TRUE)

###plot partial regression### Plotear la profundidad de la hojarasca, teniendo en cuenta que las otras variables son constantes, y los residuales parciales. Me da en negativo,por que son los valores estandarizados

effect_plot(m10, pred = av_slope, partial.residuals = TRUE, interval = TRUE, plot.points = TRUE, 
            jitter = 0.05)

#En un modelo con variables no estandarizadas
effect_plot(m10, pred = av_litter_depth, partial.residuals = TRUE, interval = TRUE, plot.points = TRUE, 
            jitter = 0.05)

avPlots(m10) #Da las regresiones parciales para cada una de las variables (es decir, que las demás variables son constantes).

# Partial regression plots using ggpredict # Predice los efectos parciales.
ggplot(ggpredict(m10, terms="av_litter_depth"), aes(x=x, y=predicted)) +
  geom_point(data=data_scaled, aes(x=av_litter_depth, y=Abundance), alpha=0.5) +
  geom_line() +
  geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha=0.2) +
  ggtitle("Partial Effect of av_litter_depth on Abundance") +
  xlab("Canopy Cover") +
  ylab("Predicted Abundance")

###choosing the best model###

#MODEL SELECTION forward and backward

library(MASS)

mfull <- lm(Abundance ~ canopy_cover + av_slope + trees_over_3m + av_litter_depth, data=data_scaled)

step <- stepAIC(mfull, trace = FALSE) #Hacer el forwart y reverse o both (ambos).
step$anova
step

best <- lm(Abundance ~ av_slope + av_litter_depth, data=data_scaled)
summary(best)

#Model selection 2 #Crear modelo y comparar AICc

AICc(m3) #MODELO NO CUADRATICO
AICc(m4) #
BIC(m1)
BIC(m2)

###Model selection 3

# Model selection using AICc (MuMIn package)
options(na.action = "na.fail")  # Required for dredge function
model_selection <- dredge(mfull, rank = "AICc") #Ranquearlos modelos por el AICc (FUNCIÓN DREDGE)
print(model_selection) 

# Best model based on AICc
best_model <- get.models(model_selection, subset = 1)[[1]]
summary(best_model)

###R-squares### Calcular los R cuadrado parciales. En este caso se sabemos que el mejor modelo es la profundidad de hojarasca, pero para este ejercicio se usará el modelo que incluye todas las variables, porque nuestroo mejor modelo sólo tiene una variable. No es lo correcto, pero es para el ejecicio.

install.packages('rsq')
library(rsq)
rsq(mfull)

# Partial R-squared for each predictor variable
partial_rsq <- rsq.partial(best)
print(partial_rsq)


####variable contribution## Hace todas las combinaciones del orden de las varibales, para ver cuál es el mejor R-squared. Serían los R-squared

install.packages("relaimpo")

library(relaimpo)

# Percentage contribution of each predictor variable
importance <- calc.relimp(best, type = "lmg")
print(importance)


plot_summs(best)


#########################################################################

#RESOLVER

install.packages("raster")
library(raster)
install.packages("terra")
library(terra)
library(dplyr)
library(ggplot2)
library(patchwork)
install.packages("rgdal")
library(rgdal)
library(dplyr)
library(magrittr)

bio_12 <- raster("bio_12.tif")
bio_1 <- raster("bio_1.tif")
bio_2 <- raster("bio_2.tif")
bio_3 <- raster("bio_3.tif")
bio_15 <- raster("bio_15.tif")
X <- raster("X.tif")
Y <- raster("Y.tif")

######plotting predictions #Unir todos los raster

layers <- stack(Y, bio_12, bio_3, bio_1, bio_15)
plot(layers)
nlayers(layers)
prediction <- predict(layers, aver, format('raster'), overwrite=TRUE)
plot(prediction)

#upload rasters

bio_12 <- raster("bio_12.tif")
bio_1 <- raster("bio_1.tif")
bio_2 <- raster("bio_2.tif")
bio_4 <- raster("bio_4.tif")
bio_15 <- raster("bio_15.tif")
X <- raster("X.tif")
Y <- raster("Y.tif")




##creating latitude and longitude rasters

# Create a new raster with the same extent and resolution as the original
Y <- bio_12
values(Y) <- yFromCell(Y, 1:ncell(Y))
# Mask the latitude raster with the original raster to maintain the shape
Y <- mask(Y, bio_12)
plot(Y)

# Alternatively, create a raster with longitude values
X <- bio_12
values(X) <- xFromCell(X, 1:ncell(X))

# Mask the longitude raster with the original raster to maintain the shape
X <- mask(X, bio_12)
plot(X)


#PLOT PARTIAL REGRESION #avsplot(bestmodel)
